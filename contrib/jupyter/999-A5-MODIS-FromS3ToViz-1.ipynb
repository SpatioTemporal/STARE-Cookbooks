{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import boto3\n",
    "import h5py\n",
    "import pyhdf\n",
    "from pyhdf.SD import SD, SDC\n",
    "\n",
    "# Why?\n",
    "import os\n",
    "import tempfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_keys(bucket, s3_client, prefix = ''):\n",
    "    \"\"\"\n",
    "    Generate the keys in an S3 bucket.\n",
    "\n",
    "    :param bucket: Name of the S3 bucket.\n",
    "    :param prefix: Only fetch keys that start with this prefix (optional).\n",
    "    \"\"\"\n",
    "    \n",
    "    kwargs = {'Bucket': bucket}\n",
    "\n",
    "    if isinstance(prefix, str):\n",
    "        kwargs['Prefix'] = prefix\n",
    "\n",
    "    done = False\n",
    "    while not done:\n",
    "        resp = s3_client.list_objects_v2(**kwargs)\n",
    "        try:\n",
    "            for obj in resp['Contents']:\n",
    "                key = obj['Key']\n",
    "                if key.startswith(prefix):\n",
    "                    # print('key: ',key)\n",
    "                    yield key\n",
    "        except KeyError:\n",
    "            print('Empty response from s3 for bucket %s with prefix %s'%(bucket,prefix))\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            kwargs['ContinuationToken'] = resp['NextContinuationToken']\n",
    "        except KeyError:\n",
    "            break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h5_dataset_from_s3(s3_client,bucket,key,filename='file.h5'):\n",
    "    buff=BytesIO()\n",
    "    s3_client.download_fileobj(bucket_name,key,buff)\n",
    "    buff.name = file_name\n",
    "    buff.seek(0)\n",
    "    return h5py.File(buff,'r') # returns an hdf5 file object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf4_dataset_from_s3(s3_client,bucket,key,filename='file.hdf'):\n",
    "    tmpdir = tempfile.TemporaryDirectory()\n",
    "    fullFilename = os.path.join(tmpdir.name,filename)\n",
    "    s3_client.download_file(bucket_name,key,fullFilename)\n",
    "    return SD(fullFilename,SDC.READ),tmpdir,fullFilename # returns an SDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "865"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_client = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GESDISC/MERRA2/2019/MERRA2_400.tavg1_2d_slv_Nx.20191203.nc4',\n",
       " 'GESDISC/MERRA2/2019/MERRA2_400.tavg1_2d_slv_Nx.20191222.nc4',\n",
       " 'GESDISC/MERRA2/2019/MERRA2_400.tavg1_2d_slv_Nx.20191226.nc4',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2300.061.2019337071951.hdf',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2300.061.2019337071951_stare.nc',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2305.061.2019337071951.hdf',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2305.061.2019337071951_stare.nc',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2310.061.2019337071934.hdf',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2315.061.2019337071952.hdf',\n",
       " 'MODAPS/MOD05/MOD05_L2.A2019336.2315.061.2019337071952_stare.nc']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = get_s3_keys('daskhub-data',s3_client,prefix='')\n",
    "key_list = [key for key in keys]; key_list[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF 4 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting: MODAPS/MOD05/MOD05_L2.A2019336.2300.061.2019337071951.hdf\n"
     ]
    }
   ],
   "source": [
    "bucket_name='daskhub-data'\n",
    "key=key_list[3]\n",
    "print('getting: %s'%(key,))\n",
    "file_name = str(\".\".join(key.split('/')[-1].split('.')[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4,tmpdir,ff_name = hdf4_dataset_from_s3(s3_client,bucket_name,key,filename=file_name) # tmpdir.cleanup() later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyhdf.SD.SD'> <class 'tempfile.TemporaryDirectory'> <class 'str'>\n",
      "/tmp/tmp07jf7o1e/MOD05_L2.A2019336.2300.061.2019337071951.hdf\n"
     ]
    }
   ],
   "source": [
    "print(type(file4),type(tmpdir),type(ff_name))\n",
    "print(ff_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Latitude', 'Longitude', 'Scan_Start_Time', 'Solar_Zenith', 'Solar_Azimuth', 'Sensor_Zenith', 'Sensor_Azimuth', 'Cloud_Mask_QA', 'Water_Vapor_Near_Infrared', 'Water_Vapor_Correction_Factors', 'Water_Vapor_Infrared', 'Quality_Assurance_Near_Infrared', 'Quality_Assurance_Infrared'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file4.datasets().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF 5 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting: GESDISC/MERRA2/2019/MERRA2_400.tavg1_2d_slv_Nx.20191226.nc4\n"
     ]
    }
   ],
   "source": [
    "bucket_name='daskhub-data'\n",
    "key=key_list[2]\n",
    "print('getting: %s'%(key,))\n",
    "file_name = str(\".\".join(key.split('/')[-1].split('.')[0:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds= h5_dataset_from_s3(s3_client,bucket_name,key,filename=file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['CLDPRS', 'CLDTMP', 'DISPH', 'H1000', 'H250', 'H500', 'H850', 'OMEGA500', 'PBLTOP', 'PS', 'Q250', 'Q500', 'Q850', 'QV10M', 'QV2M', 'SLP', 'T10M', 'T250', 'T2M', 'T2MDEW', 'T2MWET', 'T500', 'T850', 'TO3', 'TOX', 'TQI', 'TQL', 'TQV', 'TROPPB', 'TROPPT', 'TROPPV', 'TROPQ', 'TROPT', 'TS', 'U10M', 'U250', 'U2M', 'U500', 'U50M', 'U850', 'V10M', 'V250', 'V2M', 'V500', 'V50M', 'V850', 'ZLCL', 'lat', 'lon', 'time']>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:stare-1]",
   "language": "python",
   "name": "conda-env-stare-1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
